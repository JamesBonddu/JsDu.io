# 隐私计算学习资源

https://blog.csdn.net/sinat_26917383/article/details/125120167

https://github.com/ZeroWangZY/federated-learning

https://www.infoq.cn/zones/fintechathon/campus2022/support/ai

https://github.com/Echo-Wxl/Federated-Learning

https://github.com/rdragos/awesome-mpc

https://github.com/primihub/Awesome-Privacy-Computing

https://github.com/FederatedAI/Practicing-Federated-Learning

https://cloud.tencent.com/developer/article/2026578

https://github.com/Google/private-join-and-compute

https://github.com/FedML-AI/FedML/blob/master/research/Awesome-Federated-Learning.md

https://github.com/innovation-cat/Awesome-Federated-Machine-Learning

https://cn.fedai.org/

https://www.tensorflow.org/federated

https://www.tensorflow.org/federated/tutorials/tutorials_overview

# 隐私计算生命周期

数据存储
数据传输
数据计算
数据计算结果
目的解决: 大数据产品的确权，标准化, 存证, 溯源, 定价，信用体系和利益分配等一系列问题。

隐私计算的主流解决方案
- 密码学和分布式系统
- 基于硬件的可信执行环境
  - 可信执行环境 Trusted Execution Environment TEE
    - Intel SGX
    - ARM TrustZone



## 联邦学习 Federated Learning

https://federated.withgoogle.com/
https://zhuanlan.zhihu.com/p/101644082


联邦迁移学习(FederatedTransferLearning，FTL)

联邦迁移学习适用于参与方的数据样本和数据特征重叠都很少的情况。

## 联邦学习

用户数据不出本地，所有模型的训练都是在设备本地进行。本地模型训练完毕后将得到的模型参数or下降梯度，经过加密上传至云端，云端模型接收到所有上传的加密参数or梯度后，结合所有的参数值进行统一的聚合，比如通过加权平均得到新的模型参数or下降梯度，然后将新的结果再重新下发到本地，本地更新得到一个全新的模型；



### 横向联邦学习（HorizontalFederatedLearning，HFL）

横向联邦学习适用于参与方的数据特征有重叠，即数据特征在参与方之间是对齐的，但是参与方拥有的数据样本ID是不同的。它类似于在表格视图中将数据水平划分的情况，也称为按样本划分的联邦学习。

横向: 谷歌的联邦学习方案是“横向” 的，就像我们Part1.1里面说的，本地模型和云端模型用的特征都是一样的，模型的目标也是一样的。

客户端:
横向联邦学习的客户端主要功能是接收服务端的下发指令和全局模型，利用本地数据进行局部模型训练。与前一节一样，对于一个功能完善的联邦学习框架，客户端的功能同样相当复杂，比如需要考虑本地的资源（CPU、内存等）是否满足训练需要、当前的网络中断、当前的训练由于受到外界因素影响而中断等。读者如果对这些设计细节感兴趣，可以查看当前流行的联邦学习框架源代码和文档，比如FATE，获取更多的实现细节。
在客户端构造函数中，客户端的主要工作包括：首先，将配置信息拷贝到客户端中；然后，按照配置中的模型信息获取模型，通常由服务端将模型参数传递给客户端，客户端将该全局模型覆盖掉本地模型；最后，配置本地训练数据，在本案例中，我们通过torchvision 的datasets 模块获取cifar10 数据集后按客户端ID切分，不同的客户端拥有不同的子数据集，相互之间没有交集。

典型步骤:
- 每个参与方各自利用本地数据训练模型, 将计算产生的梯度加密后上传给服务器S
- 服务器S对各参与方所发送的数据进行安全聚合
- 服务器S返回更新后的结果并发送给各个参与方
- 各个参与方使用解密后的梯度更新各自的模型
- 迭代上述步骤直到损失函数收敛.

###  纵向联邦学习（VerticalFederatedLearning，VFL）

纵向联邦学习适用于联邦学习参与方的训练数据有重叠的数据样本，即参与方之间的数据样本是对齐的，但是在数据特征上有所不同。

纵向: 但是B端企业之间的模型目标不一样，特征也不一样，就像京东和腾讯，二者的用户存在重叠，但是场景不同，采集到的用户特征也存在一定差异。这种情况下的联邦学习方案我们叫做 “纵向”。

典型步骤:
- 使用PSI技术进行样本对齐.
  - 银行和商场的业务隐私数据, 在使用纵向联邦时需要对双方数据的ID进行对齐, ID-mapping
- 由协调方C向参与方A和B发送公钥, 用于对训练过程中需要交换的数据进行加密
- 参与方A和B之间以加密形式交互用于计算梯度和损失计算的中间结果
- 参与方A和B分别计算加密后的梯度值并添加掩码, 同时参与方B根据其标签数据计算加密后的损失, A 和B 把结果都汇总给协调者C
- 协调者C解密梯度和损失后回传给A和B, A和B 去除梯度信息上的掩码并更新各自模型的参数.
- 迭代2-5步直到损失函数收敛.

### 横向联邦和纵向联邦相关的核心算法
提出了FedBCD-p和FedBCD-s算法，有效地减少了客户端之间的交流次数，比起FedSGD这两个算法有更高的效率。这两个算法跟FedAvg算法类似，都是在本地更新Q轮参数，然后再跟带标签的客户端交互，他们之间的区别是：
FedAvg是横向联邦学习聚合里面的算法，需要将所有梯度收集起来然后加权平均，再发给客户机
FedBCD是纵向联邦学习里面的算法，客户机之间交互时，并不会把不属于当前机器的特征参数发过来。
同时这篇论文证明，模型精度跟本地更新参数轮数Q有关，Q取太大精度会降低，Q取太少通信成本又高了，实践表明当Q取大一点的值时FedPBCD-p算法精度比上面两个精度高。


## 密码保护技术

安全多方计算、同态加密、隐私保护的集合运算、差分隐私、秘密共享等。

混淆电路, 秘密共享, 同态加密

## 协议
多方计算协议ABY3
ABY3论文地址：https://dl.acm.org/doi/10.1145/3243734.3243760

同态加密协议
RIAC
gmpy-Paillier

FNP协议

### 不经意传输协议(Oblivious Transfer, OT), 茫然传输协议.
消息发送者讲一批消息发送给接收方, 接收方只能从中选取一条, 但是发送方无法指定是哪一条。
- 基于RSA加密算法
- 基于椭圆曲线
- 基于匿名验证隐藏证书

### 布隆过滤器 Bloom Filter

布隆过滤器是由一个固定大小的二进制向量或者位图bitmap和一系列映射函数组成.



## PSI 隐私求交

隐私保护集合交集（Private Set Intersection, PSI）协议允许持有各自隐私数据集的多方计算他们数据的交集，同时不泄露任何交集以外的信息。为了便于行文，本文假设求交发生在双方。如图1所示，假设一方持有数据集A，另一方持有数据集B，则PSI的结果为A交B。A方从B方获得的信息仅为AB的交集；同理，B方从A方获得的信息仅为AB的交集。

如图2所示，根据求交的情景进行划分，PSI大致可以分为以下四类：

（a）小集合小集合：求交双方的集合大小均较小。如，A、B双方各自持有一个包含几千个数据的集合。

（b）大集合大集合：求交双方的集合均较大。如，A、B双方各自持有一个百万以上级别的数据集合。

（c）小集合大集合：求交双方一方的集合较小，另一方的集合较大。如，A方持有一个千级别的集合，B方持有一个百万级别集合。

注：根据双方持有集合的大小是否大致相同，（a）、（b）两种情景在学术界被称为平衡PSI（balanced PSI），（c）被称为非平衡PSI（unbalanced PSI）。

（d）集合求交并计算：求交双方不仅要获得交集，还需要在交集上执行一定的运算处理，得到运算结果。如，求A、B双方的交集，并计算交集的平均值

### PSI的安全模型

半可信模型（semi-honest model）

各个参与方诚实的运行安全协议，但对协议中的数据保持好奇，即各方会尝试观察、缓存、推断别人的数据，但是不会破坏协议运行。



恶意模型（malicious model）

各个参与方会恶意的破坏协议运行（包括拒绝参与协议、修改协议执行结果、提前终止协议等）以节省自身的算力或获取其他参与方的数据。

https://bbs.huaweicloud.com/blogs/266527

https://blog.alienx.cn/2020/10/10/E10101535/

https://www.trustbe.cn/newsinfo/1773113.html

## 数据安全保护技术

1. 混淆电路
百万富翁问题
方案优化策略:
Free-XOR
行约减
Half-Gate

Object-C框架还是侧重于两方参与的隐私计算,主要支持半诚实安全模型, 涉及到多方参与就存在困难了.
https://github.com/samee/obliv-c

2. 秘密共享
将一个秘密分发给一组参与方,每个参与方只获取这个秘密的一部分，这样一个或少数几个参与方无法还原出原始的秘密，只有满足一定数量的参与方一起才能还原出原始真实的数据.

Shamir门限秘密共享.
方案:
Feldman-VSS
Pedersen-VSS

JIFF通用型隐私计算开源框架.

优化协议:
GMW协议
BGW协议
SPDZ协议
FRESCO框架

FRESCO + SPDZ 协议 考虑恶意参与方.

https://github.com/multiparty/jiff

3. 同态加密
零知识证明
SEAL
半同态加密(Partially Homomorphic Encryption, PHE) 支持对密文部分进行部分形式的计算, 例如仅支持加法或乘法操作.
- 加法同态
  - Paillier算法 联邦学习
类同态加密(SomeWhat Homomorphic Encryption, SWSWHE) 有限次同态加密, 只支持在密文上进行有限次数的加法和乘法操作.

全同态加密(Fully Homomorphic Encryption, FWHE) 全同态加密, 支持在密文上进行任意形式的计算.
- Gentry 方案
- BGV 方案
  - IBM HElib
- BFV 方案
  - 微软SEAL
- GSW 方案
- FHEW 方案
  - PALISADE 开源库
- FHEW 方案
 - PALISADE 开源库
- CKKS 方案
  - 微软SEAL
...
https://learn.microsoft.com/zh-cn/azure/architecture/solution-ideas/articles/homomorphic-encryption-seal

http://github.com/Microsoft/SEAL


谷歌开源的这个工程其实是一个翻译器，依赖于 xlscc 生成的中间文件，然后利用优化器等其它工具集，以及自身实现的代码翻译，把它转换成一个同态加密算法。

https://github.com/google/fully-homomorphic-encryption.git

https://www.freebuf.com/articles/database/278244.html


## 零知识证明

非交互零知识证明(Non-Interactivate Zero Knowledge,NIZK)
交互零知识证明(zero-knowledge Succinct Non-interactive Arguments of Knowledge)
- libsnark
https://github.com/scipr-lab/libsnark
- Spartan

## 差分隐私技术 Differential Privacy, DP

差分隐私技术是密码学的一种手段, 可以提高从统计数据库进行数据查询的准确性, 同时帮助最大限度减少识别其具体记录的机会。
差分隐私技术的核心思想是对于任意两个相差一条记录的数据集D和D'以及任意输出O,,要求添加了随机扰动的查询机制M.

安全: 除了目标记录, 攻击者知晓原数据中所有信息, 差分隐私在这个强大的假设下仍热能有效保护隐私信息.

SmartNoise
- 核心库
  - 验证程序 Validator
  - 运行时 Runtime
  - 绑定 Binding
- SDK库
  - 数据访问工具
  - REST服务工具
  - 评估器

https://smartnoise.org/
https://github.com/opendp/opendp/

分类方式
- 原始数据的存储位置
  - 中心化差分隐私
  - 本地化差分隐私
- 实现环境的交互方式
  - 交互式
  - 非交互式

经典算法
- 拉普拉斯机制
- 随机化回答机制

应用场景
- 差分隐私数据库
- 差分隐私数据合成
- 差分隐私数据采集
- 差分隐私数机器学习

电路描述语言
R1CS, QAP, TinyRAM, bacs

OPacus 利用DP-SGD差分隐私随机梯度下降.

https://github.com/pytorch/opacus

DPSQL （Differentially Private SQL Query Service）服务

https://www.anquanke.com/post/id/280300

https://zhuanlan.zhihu.com/p/571766114

# 隐私保护集合交集 PSI Private Set Intersection

指持有私有集合的参与方共同计算集合的交集, 在计算完成后, 一方或是多方得到集合正确的交集, 但不会得到集合交集以外的任何信息.

应用场景:
当集合是某个用户的通讯录
当集合是某个用户的基因诊断的基因组时
寻找共有的联系人, 并且防止交集以外的信息泄漏给任何一方.

实现方案:
1. 基于hash的PSI
2. 基于公钥加密的PSI
3. 基于混淆电路等MPC技术的PSI
4. 基于不经意传输的PSI
5. 基于全同态加密的PSI

# 隐私计算系统设计


https://arxiv.org/pdf/1902.01046.pdf

# 隐私计算框架

# FATE

https://www.bilibili.com/read/cv15004440

https://github.com/FederatedAI

https://github.com/FederatedAI/FATE/blob/3ee02ea81c62d60353b2df40e141529b151d7c67/README_zh.md

https://github.com/FederatedAI/KubeFATE/tree/master/k8s-deploy

https://www.infoq.cn/article/AoQLsGxc4bzvOKheJsAX

https://www.infoq.cn/article/PtivrDqY7l2TqXPUdD5E

## FATE DSL

FATE 使用了一套自定的领域特定语言 (DSL) 来描述任务。在 DSL 中，各种模块（例如数据读写 data_io，特征工程 feature-engineering， 回归 regression，分类 classification）可以通向一个有向无环图 （DAG） 组织起来。

https://github.com/FederatedAI/DOC-CHN/blob/master/Federatedml/%E8%BF%90%E8%A1%8C%E9%85%8D%E7%BD%AE%E8%AE%BE%E7%BD%AE%E6%8C%87%E5%8D%97.rst


# 国际比赛
iDash

http://www.humangenomeprivacy.org/2022/index.html

https://palisade-crypto.org/

https://www.iarpa.gov/research-programs/hector


# 隐私计算发展

https://nvxclouds.com/news/report/detail/25
