# 召回


## 多模态召回

https://tech.meituan.com/2020/09/27/
kdd-cup-multimodalities-recall-03.html


# 推荐系统
https://github.com/wangshusen/RecommenderSystem

https://blog.csdn.net/weixin_36604953/article/details/102652160

## 向量召回

https://www.6aiq.com/article/1601292770313


https://www.cklin.top/post/rs-greater-tui-jian-xi-tong-san-chi-xian-zhao-hui-yu-pai-xu/

推荐系统踩坑

https://zhuanlan.zhihu.com/p/337982340


爱奇艺推荐和召回
http://www.woshipm.com/pd/847004.html

pipeline构建过程

https://www.6aiq.com/article/1578982502207

## surprise推荐系统

http://surpriselib.com/

https://surprise.readthedocs.io/en/stable/

https://github.com/yzsunlei/yzsunlei.github.io/blob/master/_posts/%E7%BC%96%E7%A8%8B/2019-03-03-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84.md


# 多路召回

https://zhuanlan.zhihu.com/p/321597287

https://www.youtube.com/watch?v=ZQ1YEbFSyIQ

https://www.tvnnu.com/bianchengjishu/22194.html

https://www.git2get.com/av/105239826.html

# 推荐系统召回入门系列视频

题主的问题，以及上图的图示，其实都是一条边或者两条边，如下给下大概的解释i2i：计算item-item相似度，用于相似推荐、相关推荐、关联推荐；
u2i：基于矩阵分解、协同过滤的结果，直接给u推荐i；
u2u2i：基于用户的协同过滤，先找相似用户，再推荐相似用户喜欢的item；
u2i2i：基于物品的协同过滤，先统计用户喜爱的物品，再推荐他喜欢的物品；
u2tag2i：基于标签的泛化推荐，先统计用户偏好的tag向量，然后匹配所有的Item，这个tag一般是item的标签、分类、关键词等tag;

https://www.youtube.com/watch?v=BMtEiFKEKvE&list=PLCemT-oocgalODXpQ-EP_IfrrD-A--40h&index=3

https://zhuanlan.zhihu.com/p/260212015

https://www.zhihu.com/question/291559021

https://www.pianshen.com/article/22631558066/

https://www.cnblogs.com/by-dream/p/10450880.html

## fasttext

http://fasttext.apachecn.org/#/

# 深度学习推荐

https://www.6aiq.com/article/1584946350988

## i2i推荐

https://tech.meituan.com/2020/08/20/kdd-cup-debiasing-practice.html

https://www.upyun.com/tech/article/617/%E6%9C%89%E8%B5%9E%E4%B8%AA%E6%80%A7%E5%8C%96%E6%8E%A8%E8%8D%90%E8%83%BD%E5%8A%9B%E7%9A%84%E6%BC%94%E8%BF%9B%E4%B8%8E%E5%AE%9E%E8%B7%B5.html

https://xueqiu.com/9217191040/160568287

https://www.infoq.cn/article/0gmqhyrh0gurukap92u1

# 词向量存储格式

有三种存储格式：

txt
文本格式，类似 word 0.001233 0.34219 …
bin
google的序列化，二进制模式；
mmap
内存共享模式。一个字就是快；加载快

https://blog.csdn.net/iterate7/article/details/88938277

> word2vec文本格式

1 300
word -0.0762464299711 0.0128308048976 ... 0.0712385589283

https://stackoverflow.com/questions/49750112/gensim-how-to-load-precomputed-word-vectors-from-text-file

## gensim词向量使用

```python
#coding:utf-8
import gensim
from gensim.models import KeyedVectors

word2vec_model_path = './data/data_vec.txt' ##词向量文件的位置
word2vec_model = KeyedVectors.load_word2vec_format(word2vec_model_path, binary=False,unicode_errors='ignore')
word2vec_dict = {}
for word, vector in zip(word2vec_model.vocab, word2vec_model.vectors):
    if '.bin' not in word2vec_model_path:
        word2vec_dict[word] = vector
    else:
        word2vec_dict[word] = vector /np.linalg.norm(vector)
for each in word2vec_dict:
    print (each,word2vec_dict[each])
```

https://blog.csdn.net/yangfengling1023/article/details/81705109

https://blog.csdn.net/u010700066/article/details/83070102

https://blog.csdn.net/lilong117194/article/details/82849054

https://www.jianshu.com/p/bba1bf9518dc

http://codewithzhangyi.com/2019/12/11/using-pre-trained-word-embeddings-in-keras/

### 加速gensim使用

```python
方法 1：缩减数据集
   原始的数据集解压后有将近 16 个 G 的大小，包含 800 万个中文词汇，但是在大多数场景下，尤其是实际应用场景下，我们用到的可能也就 10 万个左右，在加载的时候可以加上 limit 参数限制数量。我设置了 limit=10000，加载的时间不超过 2 秒。

from gensim.models import KeyedVectors

file = 'data/Tencent_AILab_ChineseEmbedding/Tencent_AILab_ChineseEmbedding.txt'
wv_from_text = KeyedVectors.load_word2vec_format (file, binary=False, limit=100000)
方法 2：保存模型
   使用语料库导入到 word2vec 模型实际上我们得到的是一个前向推理的神经网络，如果我们不训练只使用这个网络做推导，在后续的使用过程中该网络的参数是不会改变的，因此我们可以保存这些参数下来，一个网络中的参数的大小肯定是远小于整个语料库的大小。而且，word2vec 模型直接加载参数肯定比从数据集中构建要快得多。我尝试保存了 10 万条数据的网络，大小不超过 5MB。如果我们想用在实时应用，我们可以先在一台性能比较好的机器上将数据导入，保存好模型参数，然后把这个参数文件放到服务器上，服务启动的时候加载就可以了。

from gensim.models import KeyedVectors

file = 'data/Tencent_AILab_ChineseEmbedding/Tencent_AILab_ChineseEmbedding.txt'
wv_from_text = KeyedVectors.load_word2vec_format (file, binary=False, limit=100000)
wv_from_text.init_sims (replace=True) # save memory to run faster

# save model for laster use
wv_from_text.save ('./test.bin')

# load model from bin file
model = KeyedVectors.load ('./test.bin')
```

http://leungyukshing.cn/archives/Gensim%E5%BF%AB%E9%80%9F%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86.html

https://stackoverflow.com/questions/42986405/how-to-speed-up-gensim-word2vec-model-load-time

Tencent AI Lab Embedding Corpus for Chinese Words and Phrases

https://ai.tencent.com/ailab/nlp/en/embedding.html

腾讯词向量使用

https://blog.csdn.net/Suan2014/article/details/83184244


## 词嵌入评测

https://wefe.readthedocs.io/en/latest/about.html


## 个性推荐

https://www.msra.cn/zh-cn/news/executivebylines/tech-bylines-personalized-recommendation-system

https://blog.csdn.net/Lynnzxl/article/details/105224788

## 推荐算法调研

http://xtf615.com/2018/05/03/recommender-system-survey/

https://www.dataapplab.com/algorithm-principle-overview-of-recommender-systems/



### 协同推荐算法

推荐系统下常常提到的一个算法就是协同过滤，我们在之前的文章当中也曾经详细写过它的原理，这里我们就不赘述了。有需要的同学可以点击下方的传送门回顾一下。这里我主要想要分享一下协同过滤的使用和特性。

SVD | 简介推荐场景中的协同过滤算法，以及 SVD 的使用

协同过滤在很长一段时间内被认为等价于推荐算法，其实这是不对的，协同过滤目前应用最广的就是一种召回的策略。它最大的用处是召回相似的商品，本质上这是一种计算商品相似度的一种算法。怎么计算商品的相似度呢？通过用户来计算，如果若干商品被类似的用户发生过行为，那么就认为它们是相似的。

但是这个只是感性的认识，对于算法而言，我们需要明确的指标以及计算方法。所以我们把用户的行为抽象成向量，通过计算向量的相似度来计算商品之间的相似度，这当然是一种近似，而且是一种粒度很粗的近似，但是对于大多数不能直接计算相似度的场景而言，这样的方式的效果还是很不错的。

协同过滤一般主要分为两种，一种叫做 i2i，一种叫做 u2i。i2i 即 item to item，也就是计算 item 之间的相似度，寻找相似 item。u2i 则是 user to item，根据用户向量寻找和用户向量相似的 item，这种应用得比较少一些。还有一种稍微冷门一些的叫做 u2u2i，也就是先找到用户的相似用户，然后再找到相似用户喜欢的 item。

https://lumingdong.cn/cooperative-recommendation-algorithms.html

## 相关竞品

https://www.sensorsdata.cn/product/recommend.html

https://www.infoq.cn/article/jb3_dhjgrcron174ucv6

# 经典论文

https://netflixtechblog.com/system-architectures-for-personalization-and-recommendation-e081aa94b5d8


# 文档如何转换成向量

https://blog.csdn.net/flyfrommath/article/details/79643233


# milvus 处理文档数据转换成向量

TaggedDocument是一个说明性类，用于表示Doc2Vec可以作为文本示例的对象。您不需要使用它 - 您只需要提供具有words属性的对象，该属性是字符串标记的列表，以及tags属性，它是标记列表与文档相关联。 （也就是说，您可以将文字示例提供为“TaggedDocument形状”或“鸭子类型”的对象。）

TaggedLineDocument是一个实用程序类，用于获取每行包含一个文档的文件，其token-wordss已经以空格分隔，并将其转换为TaggedDocument s的可迭代集合，其中每个doc将其唯一标记作为整数行号。因此，它是将文本流式传输到Doc2Vec的最小示例，对于单个doc-per-line文本文件的常见情况作为输入，并且不需要自定义的每文档标签/ ID。


https://github.com/HelWireless/doc2vec_milvus_tutorial/blob/master/5_30_doc2vec_milvus/data_processed.ipynb



句子转换为向量


作者：知乎用户
链接：https://www.zhihu.com/question/48013814/answer/344364355
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

可以用gensim包的doc2vec来将一个句子转化为句向量，具体使用代码如下：
```python
from gensim.models import Doc2Vec

# doc2vec parameters
vector_size = 300  # 300维
window_size = 15
min_count = 1
sampling_threshold = 1e-5
negative_size = 5
train_epoch = 100
dm = 0  # 0 = dbow; 1 = dmpv
worker_count = 8  # number of parallel processes

# input corpus
train_corpus = "../train_data/train_docs.txt"

def train(run_dir):
    # 训练Doc2Vec，并保存模型
    docs = gensim.models.doc2vec.TaggedLineDocument(train_corpus)
    '''
    dm: 训练算法：默认为1，指DM；dm=0，则使用DBOW
    dm_mean：当使用DM训练算法时，对上下文向量相加（默认为0）；若设为1，则求均值
    dm_concat：默认为0，当设为1时，在使用DM训练算法时，直接将上下文向量和Doc向量拼接
    dbow_words：当设为1时，则在训练doc_vector（DBOW) 的同时训练word_vector; 默认为0，只训练doc_vector，速度更快
    '''
    model = Doc2Vec(docs, size=vector_size, window=window_size, min_count=min_count, sample=sampling_threshold,
                    workers=worker_count, hs=0, dm=dm, negative=negative_size, dbow_words=1, dm_concat=1,
                    iter=train_epoch)
    model.save(os.path.join(run_dir, saved_model))  # save dov2vec
    model.wv.save_word2vec_format(os.path.join(run_dir, word_vector_path), binary=False)  # save word2vec


# 利用gensim 直接生成文档向量

def gen_d2v_corpus(self, lines):

    with open("./data/ques2_result.txt", "wb") as fw:
        for line in lines:
            fw.write(" ".join(jieba.lcut(line)) + "\n")

    sents = doc2vec.TaggedLineDocument("./data/ques2_result.txt")
    model = doc2vec.Doc2Vec(sents, size = 50, window = 5, alpha = 0.015)
    model.train(sents)

    corpus = model.docvecs
    np.save("./output/d2v.corpus.npy", corpus)

    return np.asarray(corpus)
```

https://www.zhihu.com/question/48013814


https://www.yuanmas.com/info/8VaPm97yrq.html

https://gist.github.com/Tedko/1bdb1dc7f8654c98453c42692862d200


## Milvus相似推荐

structured data ID <--> mapping table <--> Milvus ID

专利实体-标签录入 `milvus` 并生成 m_entity_id 和 tags_vector.

业务系统的 专利实体-标签 entity_id 和 tags 文本.

保障milvus 尽量实时性插入

```python
import pandas as pd

df = pd.DataFrame({
        "id": [i for i in range(nb)],
        "age": [random.randint(20, 40) for i in range(nb)],
        "embedding": [[random.random() for _ in range(dim)] for _ in range(nb)]
    })

collection, ins_res = Collection.construct_from_dataframe(
                                'my_collection',
                                df,
                                primary_field='id',
                                auto_id=False
                                )
# https://blog.51cto.com/liguodong/5110583
```

milvus 向量数据更新的最佳实践

数据更新分为实时更新和批量/全量更新两种，Milvus本身是支持实时更新的，但是数据更新时需要重新创建索引，而索引构建需要消耗大量的CPU资源，从而引发服务整体的稳定性问题。综合考虑稳定性，以及业务的数据更新场景(绝大多数是T+1更新策略)，我们采用了如图4所示的数据更新策略。

数据T+1全量更新的步骤：

全量写开始 - 删除Milvus中旧数据，清除内外id映射数据，扩容Milvus写实例。
批量写 - 向Milvus写实例批量写入数据，失败重试。
结束写 - 检验数据量是否符合预期。
触发异步建索引 - 调用Milvus建索引接口(数据量大时建索引接口可能会阻塞)。
异步等待 - 调用Milvus建索引接口返回(超时/完成)，循环判断是否建索引成功(可以根据showCollectionInfo接口的返回判断)。
引擎预热 - 让引擎把数据加载到内存中；多partition时需要遍历所有的partition才能保证所有数据都加载。
引擎切换 - A、B引擎集群角色互换，并把对应关系持久化；对原有的读集群缩容。

数据更新方案:

- 假设构建全量数据前，由集合 CollectionA 对外提供数据服务，正在使用的全量数据指向 CollectionA（redis key1 = CollectionA）。构建全量数据的目的是创建一个新的集合 CollectionB。
- 商品数据校验——检验数据库表内商品数据的条数，对比现有 CollectionA 的数据，可基于数量、百分比设置告警。如未达到设定数量（百分比），则不构建全量数据，视为本次构建失败，告警提醒；一旦达到设定数量（百分比），则启动全量构建步骤。
- 开始构建全量——初始化正在构建的全量数据的别名，更新 Redis（更新后，正在构建的全量数据的别名指向 CollectionB：redis key2 = CollectionB）。
- 创建新的全量 collection——判断 CollectionB 是否存在。假如存在，先删除再创建。
- 批量写入——对商品数据的 ID 取模，算出其所在分区的 partitionId，分批将多个分区数据写入新创建的 collection。
构建索引和预热——为新 collection 创建索引 createIndex()，索引文件存放在分布式存储服务器 GlusterFS。自动模拟请求查询新 collection，将索引内容加载到内存，实现索引预热。
- Collection 数据检验——检验新 collection 的数据，对比现有 collection 的数据，可基于数量、百分比设置告警。如未达到设定数量（百分比），则不切换 collection，视为本次构建失败，告警提醒。
- 切换 collection——别名控制。更新 Redis 后，正在使用的全量别名指向 CollectionB（redis key1 = CollectionB），同时删除 Redis key2，构建完成。


https://github.com/milvus-io/milvus/discussions/12235

https://github.com/milvus-io/milvus/issues/4303

https://milvus.io/blog/dynamic-data-update-and-query-milvus.md

https://www.6aiq.com/article/1608547494451

https://mp.weixin.qq.com/s/P87AGBPUYlo3dh1VVtBuJw

shard数据副本其实是一个非常通用也比较复杂的需求，常见的nrw和raft两类技术，而且涉及到副本故障修复工作量比较大。
milvus非常聪明的一点是充分利用现有的基础设施，元数据存储在etcd中基于raft实现好了，物理数据存储在s3之类的对象存储中，这类存储一般基于nrw模型内部实现好了。

包括实时流式数据也是，依赖kafka

https://zhuanlan.zhihu.com/p/517553501

https://milvus.io/cn/blog/2020-01-09-milvus-meta.md


## ID-Mapping 服务

https://www.biaodianfu.com/id-mapping.html

https://blog.csdn.net/Curry_lee_3/article/details/108297125

https://cloud.tencent.com/developer/article/1610320

https://www.volcengine.com/product/veCDP
https://www.volcengine.com/docs/6356/141475

## 基于 Milvus 和 MIND 算法的商品召回 召回推荐

https://aistudio.baidu.com/aistudio/projectdetail/2250360?contributionType=1&shared=1

# 搜狐新闻文本分类：机器学习大乱斗

https://www.it610.com/article/1297554426529128448.htm


# 推荐系统Rerank

推荐系统重新排序

https://www.jiqizhixin.com/articles/2019-11-12-16


# A/B测试

https://blog.back4app.com/zh/firebase%E6%9C%80%E4%BD%B3%E6%9B%BF%E4%BB%A3%E5%93%81/

推荐召回测试

https://tech.meituan.com/2017/03/24/travel-recsys.html

# 全民K歌召回路径

http://www.360doc.com/content/21/0308/21/7673502_965858335.shtml

# 重排排序逻辑

正排-痛点

各模块各自维护相应的离线和在线,稳定性和时效性无法保证;
格式多样: json、msgpack. protobuf等 ;
字段重复、含义不一致,存储不统一: mc、redis等 ;
Trouble- shooting成本比较高;
正排-统一方案

200+字段,由protobuf IDL描述，按"簇"存储;
统一离线刷新框架,保证高时效性和稳定性;
统存储和对外接口 ;
提供完善的debug工具:查询正排内容、更新时间等;


https://studygolang.com/articles/22184

http://www.woshipm.com/pd/4099114.html

# 瑞金主流的模型算法

以上模型和工作，如果让我只挑选最经典的话，我选择：

GBDT+LR
DSSM
Wide and Deep


https://www.zhihu.com/question/352306163


https://www.zybuluo.com/zakexu/note/1747732

# 汽车之家算法debug平台

https://www.infoq.cn/article/87goliaqwzw4mol0g9ke

https://bailingnan.github.io/post/shen-ru-li-jie-xgboost/

## 多路召回排序与融合策略

https://juejin.cn/post/6854573221707317261

xgboost

https://www.cnblogs.com/XDU-Lakers/p/11914401.html

https://bailingnan.github.io/post/shen-ru-li-jie-xgboost/#%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90

## 排序算法

https://zhuanlan.zhihu.com/p/138235048


https://lumingdong.cn/learning-to-rank-in-recommendation-system.html
