# spark

Apache Spark™是用于大规模数据处理的统一分析引擎


https://archive.apache.org/dist/spark/

https://repo1.maven.org/maven2/org/apache/hive/hive-jdbc/


https://spark.apache.org/

## awsome spark

https://github.com/awesome-spark/awesome-spark

https://www.cnblogs.com/qingyunzong/p/8886338.html

# spark 配置

hive2.1.1 和 spark2.1.2

https://blog.csdn.net/jobschen/article/details/78468358

https://spark.apache.org/docs/latest/sql-data-sources-hive-tables.html

https://www.huaweicloud.com/articles/12601849.html


https://blog.csdn.net/weixin_44033089/article/details/86588595

https://archive.apache.org/dist/hive/hive-2.1.1/

# hive2 外部jars包

https://cloud.tencent.com/developer/article/1621038

https://www.jianshu.com/p/86884c70b0e0

# hive spark version compare


Spark SQL 旨在与 Hive Metastore、SerDes 和 UDF 兼容。目前，Hive SerDes 和 UDF 基于 Hive 1.2.1，Spark SQL 可以连接到不同版本的 Hive Metastore（从 0.12.0 到 2.3.3。另见与不同版本的 Hive Metastore 交互）。


https://spark.apache.org/docs/2.4.5/sql-data-sources-hive-tables.html#interacting-with-different-versions-of-hive-metastore

https://spark.apache.org/docs/2.4.5/sql-migration-guide-hive-compatibility.html

https://stackoverflow.com/questions/33785843/hive-version-compatibility-with-spark



hadoop版本 ： hadoop-2.7.5

hive版本 ：apache-hive-2.1.1

spark版本： spark-2.3.0-bin-hadoop2.7

各个版本到官网下载就ok，注意的是版本之间的匹配

https://www.cnblogs.com/gxc2015/p/9035455.html

如何查看不同版本的兼容性

https://cloud.tencent.com/developer/article/1073016

https://github.com/MicrosoftDocs/azure-docs.zh-cn/blob/master/articles/synapse-analytics/spark/apache-spark-version-support.md