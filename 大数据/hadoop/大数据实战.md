# 大数据实战

https://github.com/whirlys/BigData-In-Practice

https://github.com/wangzhiwubigdata/God-Of-BigData

https://github.com/Dr11ft/BigDataGuide

https://github.com/geekyouth/SZT-bigdata

https://github.com/fayson/cdhproject


https://github.com/cloudera/cod-examples

# CDH 6.3.2 相关库依赖

CDH6.3.2 spark2.4.0 使用的scala是2.11.12 的


Component|	Component Version	Changes| Information
-|-|-
Apache Avro	| 1.8.2	| Changes
Apache Flume	| 1.9.0	| Changes
Apache Hadoop	| 3.0.0	| Changes
Apache HBase	| 2.1.4	| Changes
HBase Indexer	| 1.5	| Changes
Apache Hive	| 2.1.1	| Changes
Hue	| 4.3.0	| Changes
Apache Impala	| 3.2.0	| Changes
Apache Kafka	| 2.2.1	| Changes
Kite SDK	| 1.0.0	| Changes
Apache Kudu	| 1.10.0| 	Changes
Apache Solr	| 7.4.0	| Changes
Apache Oozie	| 5.1.0	| Changes
Apache Parquet	| 1.9.0	| Changes
Parquet-format	| 2.4.0	| Changes
Apache Pig	| 0.17.0| 	Changes
Apache Sentry	| 2.1.0	| Changes
Apache Spark	| 2.4.0	| Changes
Apache Sqoop	| 1.4.7	| Changes
Apache ZooKeeper	| 3.4.5	| Changes

https://docs.cloudera.com/documentation/enterprise/6/release-notes/topics/rg_cdh_63_maven_artifacts.html#concept_t43_r3z_rjb


https://www.cloudera.com/downloads.html

https://docs.cloudera.com/documentation/enterprise/6/release-notes/topics/rg_cdh_63_download.html#cdh_632-download

https://github.com/hm-dusk/blog_source/blob/b2c944b33f95030c617ffb620a674ff313a5940a/source/_posts/HDP%E4%B8%8ECDH%E5%AF%B9%E6%AF%94.md

## hdfs创建目录出错

```sh
[root@cdh01 bigdata-prcatice]# hdfs dfs -mkdir -p /hadoop/ch2
ocal coaa.sample.txt /hadoop/ch2mkdir: Permission denied: user=root, access=WRITE, inode="/":hdfs:supergroup:drwxr-xr-x
``

出现异常：Permission denied: user=root, access=WRITE, inode="/user":hdfs:supergroup:drwxr-xr-x

解决方案

1.修改hdfs参数  dfs.permissions=false，赋权限给root

2.重启HDFS组件，让其生效。 

3.重启成功后，shell重新登录，root执行也ok

不让其进行权限验证，

https://www.cnblogs.com/yy3b2007com/p/9953191.html

https://www.cnblogs.com/yy3b2007com/p/9962099.html#autoid-5-0-0


## 提交计算温度平均值函数到hadoop进行mapreduce计算

```sh
[root@cdh01 bigdata-prcatice]# hadoop jar ch2.noaa-1.0-SNAPSHOT.jar max.MaxTemperature /hadoop/ch2/coaa.sample.txt /hadoop/ch2/output/coaa.sample/max
T.jar min.MinTemperature /hadoop/ch2/coaa.sample.txt /hadoop/ch2/output/coaa.sample/min
hadoop jar ch2.noaa-1.0-SNAPSHOT.jar avg.AvgTemperature /hadoop/ch2/coaa.sample.txt /hadoop/ch2/output/coaa.sample/avgWARNING: Use "yarn jar" to launch YARN applications.
21/10/12 15:25:42 INFO client.RMProxy: Connecting to ResourceManager at cdh01/172.19.211.138:8032
21/10/12 15:25:42 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
21/10/12 15:25:42 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/root/.staging/job_1634023124458_0001
21/10/12 15:25:42 INFO input.FileInputFormat: Total input files to process : 1
21/10/12 15:25:42 INFO mapreduce.JobSubmitter: number of splits:1
21/10/12 15:25:42 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
21/10/12 15:25:42 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1634023124458_0001
21/10/12 15:25:42 INFO mapreduce.JobSubmitter: Executing with tokens: []
21/10/12 15:25:43 INFO conf.Configuration: resource-types.xml not found
21/10/12 15:25:43 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
21/10/12 15:25:43 INFO impl.YarnClientImpl: Submitted application application_1634023124458_0001
21/10/12 15:25:43 INFO mapreduce.Job: The url to track the job: http://cdh01:8088/proxy/application_1634023124458_0001/
21/10/12 15:25:43 INFO mapreduce.Job: Running job: job_1634023124458_0001
21/10/12 15:25:52 INFO mapreduce.Job: Job job_1634023124458_0001 running in uber mode : false
21/10/12 15:25:52 INFO mapreduce.Job:  map 0% reduce 0%
21/10/12 15:25:59 INFO mapreduce.Job:  map 100% reduce 0%
21/10/12 15:26:03 INFO mapreduce.Job:  map 100% reduce 17%
21/10/12 15:26:06 INFO mapreduce.Job:  map 100% reduce 33%
21/10/12 15:26:07 INFO mapreduce.Job:  map 100% reduce 50%
21/10/12 15:26:09 INFO mapreduce.Job:  map 100% reduce 83%
21/10/12 15:26:13 INFO mapreduce.Job:  map 100% reduce 100%
21/10/12 15:26:13 INFO mapreduce.Job: Job job_1634023124458_0001 completed successfully
21/10/12 15:26:13 INFO mapreduce.Job: Counters: 54
        File System Counters
                FILE: Number of bytes read=645490
                FILE: Number of bytes written=2827764
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=72000801
                HDFS: Number of bytes written=9
                HDFS: Number of read operations=33
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=12
                HDFS: Number of bytes read erasure-coded=0
        Job Counters 
                Launched map tasks=1
                Launched reduce tasks=6
                Data-local map tasks=1
                Total time spent by all maps in occupied slots (ms)=5039
                Total time spent by all reduces in occupied slots (ms)=12905
                Total time spent by all map tasks (ms)=5039
                Total time spent by all reduce tasks (ms)=12905
                Total vcore-milliseconds taken by all map tasks=5039
                Total vcore-milliseconds taken by all reduce tasks=12905
                Total megabyte-milliseconds taken by all map tasks=5159936
                Total megabyte-milliseconds taken by all reduce tasks=13214720
        Map-Reduce Framework
                Map input records=323654
                Map output records=321425
                Map output bytes=2892825
                Map output materialized bytes=645466
                Input split bytes=109
                Combine input records=0
                Combine output records=0
                Reduce input groups=1
                Reduce shuffle bytes=645466
                Reduce input records=321425
                Reduce output records=1
                Spilled Records=642850
                Shuffled Maps =6
                Failed Shuffles=0
                Merged Map outputs=6
                GC time elapsed (ms)=329
                CPU time spent (ms)=5750
                Physical memory (bytes) snapshot=1834012672
                Virtual memory (bytes) snapshot=18191126528
                Total committed heap usage (bytes)=1793589248
                Peak Map Physical memory (bytes)=589361152
                Peak Map Virtual memory (bytes)=2588749824
                Peak Reduce Physical memory (bytes)=216436736
                Peak Reduce Virtual memory (bytes)=2601050112
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters 
                Bytes Read=72000692
        File Output Format Counters 
                Bytes Written=9
```





























## hive 链接出错没有合适的driver

```sh
[root@cdh01 bigdata-prcatice]# java -cp jdbc-demo-1.0-SNAPSHOT.jar  com.cloudera.hivejdbc.NoneKBSimple
java.lang.ClassNotFoundException: org.apache.hive.jdbc.HiveDriver
        at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
        at java.lang.Class.forName0(Native Method)
        at java.lang.Class.forName(Class.java:264)
        at com.cloudera.hivejdbc.NoneKBSimple.<clinit>(NoneKBSimple.java:26)
通过JDBC连接非Kerberos环境下的HiveServer2
java.sql.SQLException: No suitable driver found for jdbc:hive2://cdh01:10000/
        at java.sql.DriverManager.getConnection(DriverManager.java:689)
        at java.sql.DriverManager.getConnection(DriverManager.java:270)
        at com.cloudera.hivejdbc.NoneKBSimple.main(NoneKBSimple.java:38)
```

# hive的cloudera cdh 6.3.2的connector链接驱动

https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/hive_jdbc_odbc_driver_install.html


https://docs.cloudera.com/documentation/other/connectors/hive-jdbc/2-6-11/Cloudera-JDBC-Driver-for-Apache-Hive-Release-Notes.pdf

https://docs.cloudera.com/documentation/other/connectors/hive-jdbc/2-5-6/Cloudera-JDBC-Driver-for-Apache-Hive-Install-Guide-2-5-6.pdf


https://docs.cloudera.com/documentation/other/connectors/hive-jdbc/2-6-15/Cloudera-JDBC-Driver-for-Apache-Hive-Install-Guide.pdf

https://www.h3c.com/cn/d_202105/1407508_30005_0.htm

https://blog.csdn.net/su_cicada/article/details/112263102

https://www.jianshu.com/p/47c1c013cc28

https://support.huaweicloud.com/prtg-cdh-kunpengbds/kunpenghivecdh632_02_0009.html

# spark 链接hive的坑解决

spark使用hive中有比较多的坑，尤其是版本问题引起的jar包冲突，比较好的方式是使用与CDH匹配的hive和hadoop版本，这样可以减少很多的jar冲突问题，但是在IDEA调试过程中还是难免会碰到jar包冲突问题。

https://www.cnblogs.com/chhyan-dream/p/13470523.html


## CDH 6.3.2 组件版本和Maven的依赖


大数据生态环境系统，越来越依赖CDH生态。大部分公司都是用CDH来部署大数据生态架构，这种结构是运维的一大福音，但是对于开发确实一个噩梦一样,下载CDH版本的Spark，Hadoop依赖包实在试太慢了了，甚至有可能下载不了。

直接下载国外原厂镜像，很难下载的下来。阿里云maven私服不包含CDH版本spark，hadoop依赖包，在遍历了众多国内镜像后，发现华为云包含CDH版spark,hadoop镜像。但是华为云镜像只包含CDH6.xx相关的镜像，如果基础环境还是CDH5.xx智能使用华为镜像和原厂镜像交替才实现。


```xml
<!-- pom文件中修改 -->
<repositories>
	<repository>
    	<id>cloudera</id>
        <url>https://repository.cloudera.com/artifactory/cloudera-repos/</url>
    </repository>
</repositories>

<!-- 注意需要将maven setting.xml中包含*的都要剔除掉cloudera -->
<mirror>
	<id>aliyunmaven</id>
    <mirrorOf>*,!cloudera</mirrorOf>
    <name>阿里云公共仓库</name>
    <url>https://maven.aliyun.com/repository/public</url>
</mirror>


<!-- 添加本地http, https代理方便下载国外库 -->
<proxy>
    <id>ss-http</id>
    <active>true</active>
    <protocol>http</protocol>
    <host>127.0.0.1</host>
    <port>10809</port>
    <nonProxyHosts>127.0.0.1</nonProxyHosts>
</proxy>
<proxy>
    <id>ss-https</id>
    <active>true</active>
    <protocol>https</protocol>
    <host>127.0.0.1</host>
    <port>10809</port>
    <nonProxyHosts>127.0.0.1</nonProxyHosts>
</proxy>

```

————————————————
版权声明：本文为CSDN博主「sunkl_」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/u010990043/article/details/103581898


https://blog.csdn.net/qq262593421/article/details/106229742

https://docs.cloudera.com/documentation/enterprise/6/release-notes/topics/rg_cdh_6_api_dependencies.html

https://blog.csdn.net/u010990043/article/details/103581898

https://blog.csdn.net/xwd127429/article/details/110799654

# HDP的maven依赖

https://docs.cloudera.com/HDPDocuments/HDP2/HDP-2.4.3/bk_installing_manually_book/content/ch01s13.html

所需要的链接库的驱动下载地址:


https://www.jianshu.com/p/47c1c013cc28

# hadoop 3的特性

Hadoop 3 新特征
基于JDK1.8（最低版本要求）
剔除过期的API和实现，废弃hftp转为webhfs替代
Classpath isolation：新增的防止不同版本 jar 包冲突
Shell重写 （修复了Hadoop2脚本的bug，启动时的脚本命令也有不同，建议运行Hadoop3的脚本，大概有三分之一的地方不一样）
支持HDFS的擦除编码 Erasure Encoding：默认EC策略可以节省50%的存储空间，同时还可以承受更多的存储故障（还在Haddoop2的基础上增加恢复功能）
DataNode 内部添加了负载均衡 Disk Balancer，磁盘之间的负载均衡（假定有3台服务器的磁盘都满了数据，数据存储在DataNode当中，可以在买一块磁盘插入，但其他磁盘还是满的，新磁盘是空的，这就产生了数据倾斜，所以Hadoop3提供了 Disk Balancer 磁盘平衡器自动帮我们将满磁盘分配到其他磁盘当中）
MapReduce任务级本地优化
MapReduce内存参数自动推断
mapreduce.{map,reduce}.memory.mb和mapreduce.{map,reduce}.java.opts （在Hadoop2中是需要配置这两项，但在3中就会根据任务执行级别自动推断所需要的内存，所以3比2要快）
基于 cgroup 的内存隔离和 IO Disk 隔离
支持更改分配容器的资源 Container resizing
————————————————
版权声明：本文为CSDN博主「云飞Ran」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/qq_35975685/article/details/84311627

https://www.cnblogs.com/smartloli/p/8827623.html

https://blog.csdn.net/qq_35975685/article/details/84311627


# Thrift接口

# HBase

## HBase jdbc 链接

#### 连接带有 Kerberos 认证的 Hadoop HBase Spark

https://github.com/whg517/blog/blob/master/source/_posts/programming/%E8%BF%9E%E6%8E%A5%E5%B8%A6%E6%9C%89%20Kerberos%20%E8%AE%A4%E8%AF%81%E7%9A%84%20Hadoop%20%20HBase%20Spark.md


## HBase 的thrift接口

https://blog.cloudera.com/how-to-use-the-hbase-thrift-interface-part-1/



# Impala CDH 链接

https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/impala_jdbc.html

https://docs.cloudera.com/documentation/other/connectors/impala-jdbc/2-6-20/Cloudera-JDBC-Driver-for-Impala-Install-Guide.pdf


# spark-shell 启动spark报错

```sh
[root@cdh01 tmp]# spark-shell
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
21/10/14 14:51:19 ERROR spark.SparkContext: Error initializing SparkContext.
java.lang.IllegalArgumentException: Required executor memory (1024), overhead (384 MB), and PySpark memory (0 MB) is above the max threshold (1024 MB) of this cluster! Please check the values of 'yarn.scheduler.maximum-allocation-mb' and/or 'yarn.nodemanager.resource.memory-mb'.
        at org.apache.spark.deploy.yarn.Client.verifyClusterResources(Client.scala:346)
```

调整三个配置后
```sh
#MR ApplicationMaster占用的内存量
yarn.app.mapreduce.am.resource.mb =4g
#单个节点上金额分配的物理内存总量
yarn.nodemanager.resource.memory-mb=8g
#单个任务可申请的最多物理内存量
yarn.scheduler.maximum-allocation-mb=4g
```

```sh
[root@cdh01 tmp]# spark-shell
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
21/10/14 15:14:10 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!
21/10/14 15:14:10 WARN lineage.LineageWriter: Lineage directory /var/log/spark/lineage doesn't exist or is not writable. Lineage for this application will be disabled.
Spark context Web UI available at http://cdh01:4040
Spark context available as 'sc' (master = yarn, app id = application_1634195124927_0001).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.4.0-cdh6.3.2
      /_/
         
Using Scala version 2.11.12 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_181)
Type in expressions to have them evaluated.
Type :help for more information.

scala> 
```

https://blog.csdn.net/summer089089/article/details/110640963

https://www.cnblogs.com/cenwei/p/9168490.html

https://blog.csdn.net/qq_36933797/article/details/104803288

https://www.shangmayuan.com/a/8c82dbaac3814a6c84b2d87a.html


# 常见大数据问题

## 什么是数据倾斜，怎么解决

数据倾斜在MapReduce编程模型中十分常见,用最通俗易懂的话来说,数据倾斜无非就是大量的相同key被partition分配到一个分区里,造成了'一个人累死,其他人闲死'的情况,这种情况是我们不能接受的,这也违背了并行计算的初衷,首先一个节点要承受着巨大的压力,而其他节点计算完毕后要一直等待这个忙碌的节点,也拖累了整体的计算时间,可以说效率是十分低下的。

数据倾斜发生时的现象： 

1、绝大多数task执行得都非常快，但个别task执行的极慢。 
2、原本能正常执行的Spark作业，某天突然爆出OOM（内存溢出）异常。观察异常栈，是我们写的业务代码造成的

数据倾斜发生的原理 :

在进行shuffle的时候，必须将各个节点上相同的Key拉取到某个节点上的一个task来进行处理，比如按照key进行聚合或者join操作。如果某个key对应的数据量特别大的话，会发生数据倾斜。比如大部分key对应的10条数据，但个别key却对应了100万条数据，那么大部分task会只分配到10条数据，而个别task可能会分配了100万数据。整个spark作业的运行进度是由运行时间最长的那个task决定的。 
因此出现数据倾斜的时候，spark作业看起来会运行得非常缓慢，甚至可能因为某个task处理的数据量过大导致OOM。

解决方案
1、增加jvm内存,这适用于第一种情况(唯一值非常少，极少数值有非常多的记录值(唯一值少于几千)),这种情况下,往往只能通过硬件的手段来进行调优,增加jvm内存可以显著的提高运行效率。

2、增加reduce的个数,这适用于第二种情况(唯一值比较多，这个字段的某些值有远远多于其他值的记录数，但是它的占比也小于百分之一或千分之一),我们知道,这种情况下,最容易造成的结果就是大量相同key被partition到一个分区,从而一个reduce执行了大量的工作,而如果我们增加了reduce的个数,这种情况相对来说会减轻很多,毕竟计算的节点多了,就算工作量还是不均匀的,那也要小很多。

3、自定义分区,这需要用户自己继承partition类,指定分区策略,这种方式效果比较显著。

4、重新设计key,有一种方案是在map阶段时给key加上一个随机数,有了随机数的key就不会被大量的分配到同一节点(小几率),待到reduce后再把随机数去掉即可。

5、使用combinner合并,combinner是在map阶段,reduce之前的一个中间阶段,在这个阶段可以选择性的把大量的相同key数据先进行一个合并,可以看做是local reduce,然后再交给reduce来处理,这样做的好处很多,即减轻了map端向reduce端发送的数据量(减轻了网络带宽),也减轻了map端和reduce端中间的shuffle阶段的数据拉取数量(本地化磁盘IO速率),推荐使用这种方法。


https://bbs.huaweicloud.com/blogs/detail/282280

https://blog.csdn.net/weixin_35353187/article/details/84303518

## 什么是脑裂，怎么判断脑裂

集群中的Master或Leader节点往往是通过选举产生的。在网络正常的情况下，可以顺利的选举出Leader（后续以Zookeeper命名为例）。但当两个机房之间的网络通信出现故障时，选举机制就有可能在不同的网络分区中选出两个Leader。当网络恢复时，这两个Leader该如何处理数据同步？又该听谁的？这也就出现了“脑裂”现象。

https://segmentfault.com/a/1190000040420527

https://blog.csdn.net/MyySophia/article/details/120017817

https://cloud.tencent.com/developer/article/1862729

## 拉链表是什么

拉链表是针对数据仓库设计中表存储数据的方式而定义的，顾名思义，所谓拉链，就是记录历史。记录一个事物从开始，一直到当前状态的所有变化的信息。

在数据仓库的数据模型设计过程中，经常会遇到下面这种表的设计：

- 有一些表的数据量很大，比如一张用户表，大约10亿条记录，50个字段，这种表，即使使用ORC压缩，单张表的存储也会超过100G，在HDFS使用双备份或者三备份的话就更大一些。
- 表中的部分字段会被update更新操作，如用户联系方式，产品的描述信息，订单的状态等等。
- 需要查看某一个时间点或者时间段的历史快照信息，比如，查看某一个订单在历史某一个时间点的状态。
- 表中的记录变化的比例和频率不是很大，比如，总共有10亿的用户，每天新增和发生变化的有200万左右，变化的比例占的很小。

那么对于这种表我该如何设计呢?下面有几种方案可选：

方案一：每天只留最新的一份，比如我们每天用Sqoop抽取最新的一份全量数据到Hive中。
方案二：每天保留一份全量的切片数据。
方案三：使用拉链表。

https://www.cnblogs.com/lxbmaomao/p/9821128.html

https://blog.51cto.com/u_14417862/2583089

https://blog.csdn.net/qq_46893497/article/details/110787881

## 数仓中的全量表, 快照表，增量表以及拉链表

https://www.jianshu.com/p/3bed51b8856a

https://www.jianshu.com/p/337ce248b056

# yarn 任务提交CDH报错

命令格式不正确

```sh
Error: Missing application resource.

Usage: spark-submit [options] <app jar | python file | R file> [app arguments]
Usage: spark-submit --kill [submission ID] --master [spark://...]
Usage: spark-submit --status [submission ID] --master [spark://...]
Usage: spark-submit run-example [options] example-class [example args]
```

https://blog.csdn.net/u011110301/article/details/109317354


```sh
21/10/25 14:33:29 ERROR spark.SparkContext: Error initializing SparkContext.
java.lang.IllegalArgumentException: Required executor memory (4096), overhead (409 MB), and PySpark memory (0 MB) is above the max threshold (1274 MB) of this cluster! Please check the values of 'yarn.scheduler.maximum-allocation-mb' and/or 'yarn.nodemanager.resource.memory-mb'.
        at org.apache.spark.deploy.yarn.Client.verifyClusterResources(Client.scala:346)
        at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:180)
        at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:60)
        at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:186)
        at org.apache.spark.SparkContext.<init>(SparkContext.scala:511)
        at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2549)
        at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:944)
        at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:935)
        at scala.Option.getOrElse(Option.scala:121)
```

https://blog.csdn.net/doegoo/article/details/49181173

https://blog.csdn.net/weixin_45819253/article/details/108824011


```sh
21/10/25 15:03:01 INFO yarn.Client: Preparing resources for our AM container
21/10/25 15:03:02 ERROR spark.SparkContext: Error initializing SparkContext.
org.apache.hadoop.security.AccessControlException: Permission denied: user=root, access=WRITE, inode="/user":hdfs:supergroup:drwxr-xr-x
        at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:400)
        at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:256)
        at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:194)
```

https://community.cloudera.com/t5/Support-Questions/Permission-denied-user-root-access-WRITE-inode-quot-user/td-p/4943

https://blog.csdn.net/g11d111/article/details/72902112

https://www.cnblogs.com/chenxiaoge/p/13335437.html



```sh
21/10/25 15:18:10 INFO cluster.YarnScheduler: Executor 3 on cdh04.com killed by driver.
21/10/25 15:18:10 INFO spark.ExecutorAllocationManager: Existing executor 3 has been removed (new total is 0)
21/10/25 15:18:11 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
21/10/25 15:18:12 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
```

提交代码的时候少了 --deploy-mode=cluster ，少了这个配置，程序会认为不是集群跑的，然而我的master配置的又是yarn，所以它就不认识yarn集群上的一些主机的hostname，导致如上的报错

https://www.jianshu.com/p/a054cc99e0c2