# 血缘关系案例

各类任务的血缘关系解析方式大致如下：

SQL类型：采用 Druid SQL 解析，解析源表和目标表信息。HiveSQL 使用org.apache.hadoop.hive.ql.parse 工具类解析

Spark shell：解析 Spark 的DAG信息，获取源表和目标表信息

数据同步：采用 DataX 进行数据同步，利用 DataX 的 Json 信息，解析源表和目标表

应用侧：建设模型设计模块，在数据变更时，同步进行血缘关系推送；应用侧，全部自研模块，可简单嵌入血缘采集器进行血缘信息推送

任务间：利用 Apache DolphinScheduler 的任务关系，串联表级血缘信息

数据安全模块，首先平台侧沿用 Apache DolphinScheduler 的项目管理模式，嵌入数据源隔离、用户权限、文件权限等功能，建设项目间资源隔离环境。在 Apache DolphinScheduler 上，我们在各类任务的生成上进行权限校验，统一访问平台权限中心，控制数据访问安全。

从纵向上看，在 **UniM-Data **上，我们主要借助 Apache Dolphin Scheduler 的任务调度、失败策略和补数等功能，支撑所有任务的既定计划的执行。主要从以下几方面进行了开发和适配：

https://www.cnblogs.com/DolphinScheduler/p/16427215.html

https://maimai.cn/article/detail?fid=1741156037&efid=rgX0Sp6iQXUc8dVVSHiL9A


## DQC 重构 + Spark/Hive ClientSQL Task + 血缘关系设计

血缘关系存储

neo4j存储

task content, task name, workflow name 写入 lineage server 构成血缘关系后写入graph db, 最后通过api 将数据查询出来.

sqlflow

spark
antlr4

flink
calcite

SQL类型：采用 Druid SQL 解析，解析源表和目标表信息。HiveSQL 使用org.apache.hadoop.hive.ql.parse 工具类解析
Spark shell：解析 Spark 的DAG信息，获取源表和目标表信息
数据同步：采用 DataX 进行数据同步，利用 DataX 的 Json 信息，解析源表和目标表

druid
解析包
hive-exec.jar
spark-sql.jar


# 血缘关系

https://www.mail-archive.com/search?l=commits@dolphinscheduler.apache.org&q=subject:%22%5C%5BGitHub%5C%5D+%5C%5Bdolphinscheduler%5C-website%5C%5D+JHF%5C-skyman+commented+on+a+change+in+pull+request+%23398%5C%3A+ipalfish_tech_platform.md%22&o=newest&f=1

https://zhuanlan.zhihu.com/p/408737398

基于hive的血缘关系计算

https://blog.csdn.net/master_hunter/article/details/127637747

https://github.com/OpenLineage/OpenLineage


https://egeria-project.org/features/lineage-management/overview/

https://github.com/odpi/egeria


# atlas

https://dbaplus.cn/news-73-4202-1.html
